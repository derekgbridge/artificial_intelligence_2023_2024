{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4619: Artificial Intelligence II</h1>\n",
    "<h1>Reinforcement Learning</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Reinforcement learning</h1>\n",
    "<ul>\n",
    "    <li>The agent carries out an action.</li>\n",
    "    <li>A teacher or the environment provides a <b>reward</b> (or punishment), often delayed, \n",
    "        that acts as positive (or negative) reinforcement &hellip;\n",
    "        <ul>\n",
    "            <li>&hellip; making it more (or less) likely that the agent will execute that action if it find itself in the same\n",
    "                or similar situation in the future.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>For simplicity, in this lecture, we assume a fully-observable, deterministic environment.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Reward</h1>\n",
    "<figure>\n",
    "    <img src=\"images/reward.png\" />\n",
    "</figure>\n",
    "<p style=\"font-size: 2em\">\n",
    "    $$\\v{s}_0 \\xrightarrow[\\,\\,\\,\\,\\,\\,\\,\\,r_0]{a_0\\,\\,\\,\\,\\,\\,\\,\\,} \\v{s}_1 \\xrightarrow[\\,\\,\\,\\,\\,\\,\\,\\,r_1]{a_1\\,\\,\\,\\,\\,\\,\\,\\,} \\v{s}_2 \\xrightarrow[\\,\\,\\,\\,\\,\\,\\,\\,r_2]{a_2\\,\\,\\,\\,\\,\\,\\,\\,} \\cdots$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Cumulative reward</h1>\n",
    "<ul>\n",
    "    <li>Cumulative reward: \n",
    "        $$r_0 + \\gamma r_1 + \\gamma^2r_2 + \\cdots$$    \n",
    "        or\n",
    "        $$\\sum_{t=0}^{t=\\infty}\\gamma^tr_t$$\n",
    "        where $\\gamma$ is the <b>discount rate</b> ($0 \\leq \\gamma \\leq 1$).\n",
    "    </li>\n",
    "    <li>Why do we discount?\n",
    "        <ul>\n",
    "            <li>E.g. animal behaviour, including human behaviour, shows a preference for immediate reward.</li>\n",
    "            <li>E.g. it is mathematically convenient (to overcome infinite cyclic processes; to give a preference for short solutions).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The task of the agent is to learn an action function that maximises cumulative reward.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Action-value function</h1>\n",
    "<ul>\n",
    "    <li>Assume 2 Boolean sensors and 3 actions.</li>\n",
    "    <li>Compare\n",
    "        <div style=\"display: flex; justify-content: space-between;\">\n",
    "            <table>\n",
    "                <tr><th style=\"border: 1px solid black;\">Percept</th><th style=\"border: 1px solid black;\">Action</th></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">00</td><td style=\"border: 1px solid black;\">MOVE</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">01</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">10</td><td style=\"border: 1px solid black;\">MOVE</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">11</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td></tr>\n",
    "            </table>\n",
    "            <table>\n",
    "                <tr><th style=\"border: 1px solid black;\">Percept</th><th style=\"border: 1px solid black;\">Action</th><th style=\"border: 1px solid black; width: 3em;\">$Q$</th></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">00</td><td style=\"border: 1px solid black;\">MOVE</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">00</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">00</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">01</td><td style=\"border: 1px solid black;\">MOVE</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">01</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">01</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">10</td><td style=\"border: 1px solid black;\">MOVE</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">10</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">10</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">11</td><td style=\"border: 1px solid black;\">MOVE</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">11</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "                <tr><td style=\"border: 1px solid black;\">11</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td><td style=\"border: 1px solid black;\">&hellip;</td></tr>\n",
    "            </table>\n",
    "        </div>\n",
    "    </li>\n",
    "    <li>Class exercise: Suppose the agent has $m$ touch sensors (returning 0 or 1) and $n$ different actions. \n",
    "        How many rows will the table contain?\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>What is $Q$?</h1>\n",
    "<ul>\n",
    "    <li>$Q(\\v{s}, a)$ is an <em>estimate</em> of the cumulative reward the agent will receive if, \n",
    "        having sensed $\\v{s}$, it chooses to execute action $a$.\n",
    "    </li>\n",
    "    <li>Hence, having sensed $\\v{s}$, choose action $a$ for which $Q(\\v{s}, a)$ is highest:\n",
    "        $$\\argmax_a Q(\\v{s},a)$$\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Class exercise</h1>\n",
    "<ul>\n",
    "    <li>Given this table\n",
    "        <table>\n",
    "            <tr><th style=\"border: 1px solid black;\">Percept</th><th style=\"border: 1px solid black;\">Action</th><th style=\"border: 1px solid black;\">$Q$</th></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">$\\vdots$</td><td style=\"border: 1px solid black;\">$\\vdots$</td><td style=\"border: 1px solid black;\">$\\vdots$</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">01</td><td style=\"border: 1px solid black;\">MOVE</td><td style=\"border: 1px solid black;\">0.2</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">01</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td><td style=\"border: 1px solid black;\">0.1</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">01</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td><td style=\"border: 1px solid black;\">0.7</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">$\\vdots$</td><td style=\"border: 1px solid black;\">$\\vdots$</td><td style=\"border: 1px solid black;\">$\\vdots$</td></tr>\n",
    "        </table>   \n",
    "    </li>\n",
    "    <li>Suppose $\\v{s}$ is 01</li>\n",
    "    <li>What is $\\argmax_a Q(\\v{s},a)$?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>$Q$-learning</h1>\n",
    "<ul>\n",
    "    <li>Start with random $Q$-values (or all zero).</li>\n",
    "    <li>Improve by trial-and-error: choose actions, get rewards, update $Q$-values.</li>\n",
    "</ul>\n",
    "<figure style=\"border: 1px solid black; background-color: #D0D0D0\">\n",
    "    <figcaption style=\"border-bottom: 1px solid black\">\n",
    "        QLearning($\\epsilon$)\n",
    "    </figcaption>\n",
    "    <ul>\n",
    "        <li>$\\v{s} = \\mathit{SENSE}()$;</li>\n",
    "        <li>do forever\n",
    "            <ul>\n",
    "                <li>$\\mathit{rand} = $ a randomly-generated number in $[0,1)$;</li>\n",
    "                <li>if $\\mathit{rand} < \\epsilon$\n",
    "                    <ul>\n",
    "                        <li>Choose action $a$ randomly;</li>\n",
    "                    </ul>\n",
    "                    else\n",
    "                    <ul>\n",
    "                        <li>$a = \\argmax_a Q(\\v{s}, a)$;</li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>$r = \\mathit{EXECUTE}(a)$;</li>\n",
    "                <li>$\\v{s}' = \\mathit{SENSE}()$;</li>\n",
    "                <li>$Q(\\v{s}, a) = r + \\gamma \\times \\max_{a'} Q(\\v{s}', a')$;</li>\n",
    "                <li>$\\v{s} = \\v{s}'$;</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Exploration vs. Exploitation</h1>\n",
    "<ul>\n",
    "    <li>Exploration:\n",
    "        <ul>\n",
    "            <li>Choose an action which may not be the best action according to the current $Q$-values.\n",
    "                But it may gain you new experience and improve the $Q$-values.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Exploitation:\n",
    "        <ul>\n",
    "            <li>Choose the action which is best according to the current $Q$-values.\n",
    "                It may gain you reward.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The so-called <b>$\\epsilon$-greedy policy</b> (where $0 \\leq \\epsilon \\leq 1$) is the simplest way to balance exploration and exploitation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Updating $Q$-values</h1>\n",
    "<ul>\n",
    "    <li>From the algorithm:\n",
    "        $$Q(\\v{s}, a) = r + \\gamma \\times \\max_{a'}Q(\\v{s}', a')$$\n",
    "    </li>\n",
    "    <li>The new value is the reward for the latest action $r$ plus our highest current estimate of the cumulative reward\n",
    "        it can receive.\n",
    "    </li>\n",
    "    <li>Over the course of repeated actions, the $Q$-values will get better and better:\n",
    "        <ul>\n",
    "            <li>When one $Q$-value improves then the $Q$-values of its immediate predecessors will also improve\n",
    "                next time they get updated.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Class exercise</h1>\n",
    "<ul>\n",
    "    <li>Given this table\n",
    "        <table>\n",
    "            <tr><th style=\"border: 1px solid black;\">Percept</th><th style=\"border: 1px solid black;\">Action</th><th style=\"border: 1px solid black; width: 3em;\">$Q$</th></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">$\\vdots$</td><td style=\"border: 1px solid black;\">$\\vdots$</td><td style=\"border: 1px solid black;\">$\\vdots$</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">10</td><td style=\"border: 1px solid black;\">MOVE</td><td style=\"border: 1px solid black;\">5</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">10</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td><td style=\"border: 1px solid black;\">4</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">10</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td><td style=\"border: 1px solid black;\">1</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">11</td><td style=\"border: 1px solid black;\">MOVE</td><td style=\"border: 1px solid black;\">0</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">11</td><td style=\"border: 1px solid black;\">TURN(RIGHT, 2)</td><td style=\"border: 1px solid black;\">4</td></tr>\n",
    "            <tr><td style=\"border: 1px solid black;\">11</td><td style=\"border: 1px solid black;\">TURN(LEFT, 2)</td><td style=\"border: 1px solid black;\">6</td></tr>\n",
    "        </table>   \n",
    "    </li>\n",
    "    <li>Suppose current percept is 10.<br />\n",
    "        Assuming exploitation, which action will be chosen?</li>\n",
    "    <li>Suppose reward is 3, next percept is 11 and $\\gamma$ is 1.<br />\n",
    "        Using $Q(\\v{s}, a) = r + \\gamma \\times \\max_{a'} Q(\\v{s}', a')$, update the table.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Types of Learning in AI</h1>\n",
    "<ul>\n",
    "    <li><b>Reinforcement learning</b>:\n",
    "        <ul>\n",
    "            <li>The agent receives rewards (or punishments) after executing actions.</li>\n",
    "            <li>The rewards (or punishments) act as positive (or negative) reinforcement.</li>\n",
    "            <li>The agent learns a policy that defines which actions to perform in which situations to\n",
    "                maximize reward over time.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Unsupervised learning</b>:\n",
    "        <ul>\n",
    "            <li>The agent learns from an unlabeled dataset.</li>\n",
    "            <li>The goal is to find structure within the dataset.</li>\n",
    "            <li>Clustering and most forms of dimensionality reduction are examples of unsupervised\n",
    "                learning but there are other examples of unsupervised learning (not covered) such as anomaly detection and\n",
    "                association rule mining.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Supervised learning</b>:\n",
    "        <ul>\n",
    "            <li>The agent learns from a labeled dataset.</li>\n",
    "            <li>The goal is to generalise from the labeled dataset to learn how to predict \n",
    "                target values/class labels when given feature values.\n",
    "            </li>\n",
    "            <li>Learning models for regression and classification are examples of supervised learning.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Semisupervised learning</b>:\n",
    "        <ul>\n",
    "            <li>The agent learns from a dataset, only a (small) subset of which is labeled.</li>\n",
    "            <li>The goal is usually the same as in supervised learning but making use of the\n",
    "                unlabeled data to compensate for the low volume of labeled data.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Concluding remarks</h1>\n",
    "<ul>\n",
    "    <li>Reinforcement Learning underpins a lot of current success in game playing.</li>\n",
    "    <li>But it is seeing real use in other areas, e.g. robot motion control, recommender systems.</li>\n",
    "    <li>For real use, you need more sophisticated algorithms:\n",
    "        <ul>\n",
    "            <li>To handle non-deterministic environments;</li>\n",
    "            <li>To improve convergence;</li>\n",
    "            <li>To build a model of the environment;</li>\n",
    "            <li>To scale up, and</li>\n",
    "            <li>To represent the policy in a way that allows the agent to generalise from what it learns.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We'll look at the last of these in the next lecture.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
